{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# **NLP Mini Chatbot - Intent Classification (SmartSaku)**\n",
    "\n",
    "Notebook ini berisi langkah-langkah untuk melatih model _Machine Learning_ yang berfungsi sebagai otak dari chatbot. Tujuannya adalah untuk mengklasifikasikan maksud (intent) dari input teks pengguna.\n",
    "\n",
    "Prosesnya meliputi:\n",
    "1.  **Impor Library**: Memuat semua pustaka Python yang dibutuhkan.\n",
    "2.  **Muat Dataset**: Membaca data latih dari file `dataset_chatbot.csv`.\n",
    "3.  **Ekstraksi Fitur (TF-IDF)**: Mengubah data teks menjadi representasi numerik.\n",
    "4.  **Pelatihan Model (SVM)**: Melatih model untuk mengenali pola dan memprediksi intent.\n",
    "5.  **Simpan Model**: Menyimpan model dan vectorizer yang sudah dilatih agar bisa digunakan nanti oleh aplikasi backend."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Import Library\n",
    "Import semua library yang dibutuhkan untuk preprocessing, training, evaluasi, dan penyimpanan model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Semua library yang dibutuhkan berhasil di-import.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.svm import SVC\n",
    "import pickle\n",
    "\n",
    "print(\"Semua library yang dibutuhkan berhasil di-import.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Muat Dataset\n",
    "\n",
    "Langkah pertama adalah memuat dataset yang telah kita siapkan sebelumnya. Kita akan menggunakan library `pandas` untuk membaca file `dataset_chatbot.csv` ke dalam sebuah DataFrame.\n",
    "\n",
    "Setelah dimuat, kita akan:\n",
    "- Menampilkan 5 baris pertama untuk memastikan data terbaca dengan benar.\n",
    "- Memisahkan kolom `text` (sebagai fitur atau `X`) dan `intent` (sebagai target atau `y`).\n",
    "- Menghapus baris yang kosong (`dropna`) untuk menjaga kualitas data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset berhasil dimuat.\n",
      "Jumlah data: 139\n",
      "\n",
      "Contoh data:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>intent</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>halo</td>\n",
       "      <td>sapaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hai</td>\n",
       "      <td>sapaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>selamat pagi</td>\n",
       "      <td>sapaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>selamat siang</td>\n",
       "      <td>sapaan</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>selamat sore</td>\n",
       "      <td>sapaan</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            text  intent\n",
       "0           halo  sapaan\n",
       "1            hai  sapaan\n",
       "2   selamat pagi  sapaan\n",
       "3  selamat siang  sapaan\n",
       "4   selamat sore  sapaan"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "try:\n",
    "    # Membaca dataset\n",
    "    df = pd.read_csv('dataset_chatbot.csv')\n",
    "    \n",
    "    # Menghapus baris yang mungkin kosong\n",
    "    df.dropna(subset=['text', 'intent'], inplace=True)\n",
    "    \n",
    "    # Memisahkan fitur (X) dan target (y)\n",
    "    X = df['text']\n",
    "    y = df['intent']\n",
    "    \n",
    "    print(\"Dataset berhasil dimuat.\")\n",
    "    print(\"Jumlah data:\", len(df))\n",
    "    print(\"\\nContoh data:\")\n",
    "    display(df.head())\n",
    "    \n",
    "except FileNotFoundError:\n",
    "    print(\"Error: File 'dataset_chatbot.csv' tidak ditemukan. Pastikan file ada di direktori yang sama dengan notebook ini.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Ekstraksi Fitur dengan TF-IDF Vectorizer\n",
    "\n",
    "Model _machine learning_ tidak bisa memproses teks mentah, jadi kita perlu mengubahnya menjadi angka. Kita akan menggunakan metode **TF-IDF (Term Frequency-Inverse Document Frequency)**.\n",
    "\n",
    "- **TF (Term Frequency)**: Mengukur seberapa sering sebuah kata muncul dalam satu kalimat.\n",
    "- **IDF (Inverse Document Frequency)**: Mengukur seberapa penting sebuah kata di seluruh dataset.\n",
    "\n",
    "Proses ini akan mengubah setiap kalimat menjadi sebuah vektor angka."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ekstraksi fitur dengan TF-IDF berhasil.\n",
      "Dimensi dari matriks fitur: (139, 269)\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer()\n",
    "\n",
    "# Melatih vectorizer dan mentransformasi data teks\n",
    "X_vectorized = vectorizer.fit_transform(X)\n",
    "\n",
    "print(\"Ekstraksi fitur dengan TF-IDF berhasil.\")\n",
    "print(\"Dimensi dari matriks fitur:\", X_vectorized.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Pelatihan Model Klasifikasi\n",
    "\n",
    "Sekarang kita memiliki data dalam format numerik. Langkah selanjutnya adalah melatih model klasifikasi. Kita akan menggunakan **Support Vector Classifier (SVC)**, yang merupakan salah satu algoritma yang handal untuk tugas klasifikasi teks.\n",
    "\n",
    "Model ini akan belajar dari `X_vectorized` (fitur) dan `y` (label intent) untuk menemukan pola yang membedakan satu intent dari yang lain."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memulai pelatihan model...\n",
      "Model berhasil dilatih!\n"
     ]
    }
   ],
   "source": [
    "# Inisialisasi model SVC\n",
    "# kernel='linear' cocok untuk data teks\n",
    "# probability=True agar kita bisa mendapatkan skor kepercayaan nanti\n",
    "model = SVC(kernel='linear', probability=True)\n",
    "\n",
    "# Melatih model dengan data\n",
    "print(\"Memulai pelatihan model...\")\n",
    "model.fit(X_vectorized, y)\n",
    "print(\"Model berhasil dilatih!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Simpan Model dan Vectorizer\n",
    "\n",
    "Langkah terakhir dan paling penting adalah menyimpan hasil kerja kita. Kita akan menyimpan dua objek:\n",
    "1.  **`model`**: Model SVC yang sudah dilatih.\n",
    "2.  **`vectorizer`**: Objek TF-IDF yang tahu bagaimana cara mengubah teks baru menjadi format angka yang sama seperti saat pelatihan.\n",
    "\n",
    "Kita menggunakan `pickle` untuk menyimpan objek-objek ini ke dalam file biner (`.pkl`). File-file inilah yang nantinya akan kita serahkan ke tim backend."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Proses Selesai!\n",
      "Dua file telah berhasil dibuat:\n",
      "1. model_chatbot.pkl\n",
      "2. vectorizer.pkl\n"
     ]
    }
   ],
   "source": [
    "# Menyimpan model ke file .pkl\n",
    "with open('model_chatbot.pkl', 'wb') as model_file:\n",
    "    pickle.dump(model, model_file)\n",
    "\n",
    "# Menyimpan vectorizer ke file .pkl\n",
    "with open('vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "\n",
    "print(\"Proses Selesai!\")\n",
    "print(\"Dua file telah berhasil dibuat:\")\n",
    "print(\"1. model_chatbot.pkl\")\n",
    "print(\"2. vectorizer.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_gpu",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
